# 依赖说明

```java
// redis java端的依赖			
<dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-data-redis</artifactId>
        </dependency>
  // redis数据库连接池的依赖
        <dependency>
            <groupId>org.apache.commons</groupId>
            <artifactId>commons-pool2</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>

        <dependency>
            <groupId>mysql</groupId>
            <artifactId>mysql-connector-java</artifactId>
            <scope>runtime</scope>
            <version>5.1.47</version>
        </dependency>
  // 提供一些方便的注解
        <dependency>
            <groupId>org.projectlombok</groupId>
            <artifactId>lombok</artifactId>
            <optional>true</optional>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-test</artifactId>
            <scope>test</scope>
        </dependency>
  // mybatis单表增删改查的简化
        <dependency>
            <groupId>com.baomidou</groupId>
            <artifactId>mybatis-plus-boot-starter</artifactId>
            <version>3.4.3</version>
        </dependency>
        <!--hutool-->
  // json处理、字符串处理等工具类
        <dependency>
            <groupId>cn.hutool</groupId>
            <artifactId>hutool-all</artifactId>
            <version>5.7.17</version>
        </dependency>
```

# 短信登录功能

### 基于session实现

dto：DTO就是数据传输对象(Data Transfer Object)的缩写。 DTO模式，是指将数据封装成普通的JavaBeans，在J2EE多个层次之间传输。 DTO类似信使，是同步系统中的Message。 该JavaBeans可以是一个数据模型Model。  

使用接口中没有的方法，写出来后直接根据提示创建接口方法在相应的接口中就行，跳到接口中后再次点击左边中的绿色小圆点（小圆点中有个I）直接跳转到接口的实现类中去

# ThreadLocal

<img src="img/%E6%88%AA%E5%B1%8F2022-10-17%2009.51.32.png" alt="截屏2022-10-17 09.51.32" style="zoom:50%;" />

每个线程都会有属于自己的本地内存，在堆（也就是上图的主内存）中的变量在被线程使用的时候会被复制一个副本线程的本地内存中，当线程修改了共享变量之后就会通过JMM管理控制写会到主内存中。

 很明显，在多线程的场景下，当有多个线程对共享变量进行修改的时候，就会出现线程安全问题，即数据不一致问题。常用的解决方法是对访问共享变量的代码加锁（synchronized或者Lock）。但是这种方式对性能的耗费比较大。在JDK1.2中引入了ThreadLocal类，来修饰共享变量，使每个线程都单独拥有一份共享变量，这样就可以做到线程之间对于共享变量的隔离问题。

**JDK8之后，每个Thread维护一个ThreadLocalMap对象，这个Map的key是ThreadLocal实例本身，value是存储的值要隔离的变量，是泛型**

一般都会将ThreadLocal声明成一个静态字段，因为线程里面有私有的Map变量去存储各个ThreadLocal的value，map的key就是ThreadLocal对象，想要获取就必须获得ThreadLoacl对象，**不同的线程拿到相同的ThreadLocal在自己线程的map中获取value也不同。**

ThreadLocal对象里面的save方法首先就会拿到当前线程，然后再往下进行，这样就顺起来了

**就是为了给线程这个对象注入自己的私有变量（User对象），每个线程都读自己被注入的属性，但是ThreadLocal又作为公共的key，可以在任何地方写**

# 拦截器

**将校验用户是否登录的操作代码提取出来，其他的各种Controller就不用再校验，拦截器将校验出来的结果通过ThreadLocal进行传递，完美这样子，看一下线程对于tomcat 的意义**

1、编写拦截器的代码，继承HandlerInterceptor，里面的三个方法返回值为boolean，并且是这个接口的default方法，就算不implement也能够使用

2、将便携好的拦截器配到spring中去。

* 新建一个配置类实现WebMvcConfigurer接口
* 覆盖方法addInterceptors，使用方法的形参对象的addInterceptor中放入new好的刚刚写的拦截器类的对象，再配置一下路径
* 最后上面加上Configuration的注解即可

拦截器里面的redis注入只能通过构造函数进行注入，因为拦截器的代码是写在一个里面，这个类是不进行spring注入的

**看代码的报错直接看第一行的报错或者看log信息**

# Redis短信登录

Tomcat的session共享比较la，建议使用redis集群来取代session机制

在发送短信验证码时的key使用电话号码取代session的code属性，在验证用户是否登录时key使用token来取代session的user属性

## 两个拦截器的作用

<img src="img/%E6%88%AA%E5%B1%8F2022-11-06%2016.45.31.png" alt="截屏2022-11-06 16.45.31" style="zoom:80%;" />

第一个拦截器只是查看当前用户的token有没有以及有没有过期，有token并且没过期就放入ThreadLocal中去方便需要用户信息的拦截器获取，并且刷新token的有效期，这个拦截器不会拦截，放行所有请求，唯一的目的就是为了刷新tocken，**因为用户访问网站的所有网页都需要刷新tocken，但是并不是所有的网页都需要token信息，所以只能这样写而不是将刷新token写到第二个拦截器中**

# 缓存

## 缓存更新策略

1、**内存淘汰：**redis自动进行，当redis内存达到咱们设定的max-memery的时候，会自动触发淘汰机制，淘汰掉一些不重要的数据(可以自己设置策略方式)。无维护成本，但是一致性很差，**感觉就没有一致性的保证**

2、**超时剔除：**当我们给redis设置了过期时间ttl之后，redis会将超时的数据进行删除，方便咱们继续使用缓存。**这个也基本没有一致性**

3、**主动更新：**我们可以手动调用方法把缓存删掉，通常用于解决缓存和数据库不一致问题

**使用主动更新加上兜底（超时剔除）来保证高一致性**

## 主动更新的策略

1、**操作数据库更新数据后，删除缓存而不是更新缓存**。假设我们每次操作数据库后，都操作缓存，但是中间如果没有人查询，那么这个更新动作实际上只有最后一次生效，中间的更新动作意义并不大

2、**先操作数据库，再删除缓存**。原因在于，如果你选择第一种方案，在两个线程并发来访问时，假设线程1更新数据库，他**先把缓存删了**，此时线程2过来，他查询缓存数据并不存在，此时他写入缓存（查到的还是旧数据），当他写入缓存后，线程1再执行更新动作时（因为是先操删缓存后操作的数据库），实际上写入的就是旧的数据，新的数据被旧数据覆盖了。这就导致了缓存更新不到最新值

<img src="img/%E6%88%AA%E5%B1%8F2022-11-06%2020.01.12.png" alt="截屏2022-11-06 20.01.12" style="zoom:80%;" />

**但其实先操作数据库后删除缓存可以保证缓存可以更新到最新值，但是当数据库更新完毕没有删除缓存时，拿到的还是旧值，会有一个间隙的数据不一致**

两部分逻辑，第一部分是将数据从数据库放入缓存

第二部分才是这个数据库更新后操作缓存的逻辑

## 将数据放入缓存的逻辑操作

1、查询redis缓存

2、存在返回成功，不存在去数据库查询

3、数据库查询不到返回失败，查询到了就放入缓存中，**同时设置过期时间作为兜底**，然后返回查询结果

## 数据库更新后操作缓存的逻辑

**拦截器的拦截地址一定要加“/”，一定要是斜杠开头**

1、获取id

2、传入的id为空，就返回失败

3、**更新数据库，删除缓存，返回ok**

4、**给这一系列操作加上事务**

# 缓存穿透

用户请求的数据在缓存中和数据库中都不存在，不断发起这样的请求，给数据库带来巨大压力

解决方案

1、布隆过滤器

布隆过滤器原理：

布隆过滤器的实现原理是一个超大的**位数组**和**几个哈希函数**。假设有K个哈希函数，对于集合里面的每一个元素，将元素依次通过 k个哈希函数进行映射，每次映射都会产生一个哈希值，这个值对应位数组上面的一个点，然后将位数组对应的位置标记为 1。查询某元素是否存在集合中的时，用同样的方法将 W 通过哈希映射到位数组上的 3 个点。如果 3 个点中任意一个点不为 1，则可以判断该元素一定不存在集合中。反之，如果 3 个点都为 1，则该元素可能存在集合中。注意：此处不能判断该元素是否一定存在集合中，可能存在一定的误判率

2、缓存null值

3、增加id复杂度，避免猜测

4、做好数据的基础格式校验

5、加强用户权限

6、做好热点参数的限流

直接加两句代码就解决了

# 缓存雪崩

缓存雪崩是指在同一时段**大量的缓存key同时失效或者Redis服务宕机**，导致大量请求到达数据库，带来巨大压力。

解决方案：

* 给不同的Key的TTL添加随机值
* 利用Redis集群提高服务的可用性
* 给缓存业务添加降级限流策略
* 给业务添加多级缓存

<img src="img/%E6%88%AA%E5%B1%8F2022-11-14%2019.42.48.png" alt="截屏2022-11-14 19.42.48" style="zoom:80%;" />

# 缓存击穿

缓存击穿问题也叫热点Key问题，就是一个被高并发访问**并且缓存重建业务较复杂**的key突然失效了，无数的请求访问会在瞬间给数据库带来巨大的冲击。

就是说这个key的缓存失效了，需要从数据库拿出来重新缓存一下，但是这个过程的时间较长，在这个过程中，恰巧这个key还是一个热点key，很多请求都在这个时间段来了，发现没有缓存，然后都去数据库找，准备重建缓存，这不就崩了

**缓存穿透是两层，击穿就是击穿了缓存层。穿透比较彻底**

<img src="img/%E6%88%AA%E5%B1%8F2022-11-14%2020.28.29.png" alt="截屏2022-11-14 20.28.29" style="zoom:80%;" />

解决方案一、使用锁来解决：

因为锁能实现互斥性。假设线程过来，只能一个人一个人的来访问数据库，从而避免对于数据库访问压力过大，但这也会影响查询的性能，因为此时会让查询的性能从并行变成了串行，我们可以采用tryLock方法 + double check来解决这样的问题。

假设现在线程1过来访问，他查询缓存没有命中，但是此时他获得到了锁的资源，那么线程1就会一个人去执行逻辑，假设现在线程2过来，线程2在执行过程中，并没有获得到锁，那么线程2就可以进行到休眠，直到线程1把锁释放后，线程2获得到锁，然后再来执行逻辑，此时就能够从缓存中拿到数据了。

解决方案二、逻辑过期方案

方案分析：我们之所以会出现这个缓存击穿问题，主要原因是在于我们对key设置了过期时间，假设我们不设置过期时间，其实就不会有缓存击穿的问题，但是不设置过期时间，这样数据不就一直占用我们内存了吗，我们可以采用逻辑过期方案。

我们把过期时间设置在 redis的value中，注意：这个过期时间并不会直接作用于redis，而是我们后续通过逻辑去处理。假设线程1去查询缓存，然后从value中判断出来当前的数据已经过期了，此时线程1去获得互斥锁，那么其他线程会进行阻塞，获得了锁的线程他会开启一个 线程去进行 以前的重构数据的逻辑，直到新开的线程完成这个逻辑后，才释放锁， 而线程1直接进行返回，假设现在**线程3过来访问，由于线程线程2持有着锁，所以线程3无法获得锁，线程3也直接返回数据**，只有等到新开的线程2把重建数据构建完后，其他线程才能走返回正确的数据。

这种方案巧妙在于，异步的构建缓存，缺点在于在构建完缓存之前，**返回的都是脏数据**。直接看图片就行，**在重建完成之前返回的都是过期的数据**

![截屏2022-11-14 20.30.41](img/%E6%88%AA%E5%B1%8F2022-11-14%2020.30.41.png)

# 使用互斥锁解决缓存击穿

## 利用redis的键做分布式锁

redis中有一个setnx（set key **only if not exist**），只有key不存在才会成功，存在了就不会成功。redis又是单线程，所以就能当锁，牛逼

**释放锁的时候就把他删掉 del key，加一个有效期作为兜底**

**当拿到锁的时候应该double check一下，参考多线程的设计模式**

# 使用逻辑过期方式解决缓存击穿

为key设置一个逻辑过期时间，当检查到过期时使用互斥锁去新建一个线程更新缓存，然后立即返回这个过期缓存。理论上逻辑过期时互斥锁的复杂版，他一致性会差一点，慢一点儿

# 分布式系统下唯一随机ID的生成

 就是在前面加了32位的时间差转换成的时间戳再与上一个32位的自增键，按照每天设置一个不同键，键就用日期来设置。这样设置，UUID不能保证单调递增，这个可以，而且性能比UUID好

# 秒杀券

注意秒杀券的截止时间要设置成大于当前的时间前端才能够显示

1、判断时间是否在规定的时间内

2、判断库存

3、update数据库，将库存的值减一，判断数据是否更新成功

4、生成优惠券订单的id，关联优惠券和用户的id，总共三个id

5、写入优惠券订单表，但会成功

6、给方法加上事务

## 超卖问题

本质就是多线程的问题

使用CAS无锁（乐观锁）的方式，mysql的update是自己有锁的，锁的类型有点复杂，以后再看

# 一人一单问题

之前使用无锁的方式是因为是修改操作

**一人一单问题判断的是记录存不存在，就是存在问题，就不能使用无锁的方式**

使用悲观锁

1、降低锁的粒度，使用userID加锁，并使用String的intern方法（感觉会被回收器回收，不一定可靠）

2、锁的范围要大于事务范围，但是事务的代码使用代理对象生成的，因此，在锁的代码块中，应该使用代理对象调用事务的代码

感觉怎么看都不可靠

# 在集群下的并发问题

在集群的时候，jvm不同，锁就不同了，就有问题了

idea开启两个相同服务：

1、在左下角的Service中点击原本的8081项目，右击，拷贝配置

2、在弹出的界面中给vmoptinos中修改端口 -Dserver.port=8082，确定即可，然后就能一起启动了

在nginx开启负载均衡

1、修改代理的语句为：

```xml
proxy_pass http://backend;
```

2、修改backend

```xml
upstream backend {
        server 192.168.248.58:8081 max_fails=5 fail_timeout=10s weight=1;
        server 192.168.248.58:8082 max_fails=5 fail_timeout=10s weight=1;
    } 
```

nginx默认时轮询机制，一人一次轮回来

并发问题不好延时，要用debug来，跳过，反正就是这个锁名义上一样，但是不在同一个虚拟机中就不一样了，可以同时进入两个线程进行抢单，同一个人就能下单两次

**搞清楚要看的是同一个人在并发下同时抢单的问题**，**所以锁应该用用户ID，降低锁的粒度**

# 分布式锁

简单的使用redis锁，redis锁的过期时间要大于预估的业务执行的最长时间。当获取redis锁之前就已经判断了当前用户没有下过单以及库存充足的问题，为了防止并发多次下单问题才使用的分布式锁。简单的设置，在获取锁代码不出异常的时候应该是可以用的，在集群下测试也是正常

# 分布式锁误删的情况

1、持有锁的线程内部执行代码时间过长，导致分布式锁超时自动释放。这时第二个线程就可以拿到锁，然后第一个线程执行完又给线程二的锁删了，线程三又进来了。这样就有两个阶段是有两个线程并行在执行。**在执行一人一单的时候就可能发生一个人下单三次**

![截屏2022-11-25 18.44.12](img/%E6%88%AA%E5%B1%8F2022-11-25%2018.44.12.png)

解决办法，在获取锁的时候把锁的value存入线程的唯一标识符（UUID加上线程id）。解锁的时候，首先判断锁是否是本线程设置的锁，如果不是就不删除

2、更极端的情况，线程一已经判断了这个锁是本线程的锁，但是准备删除的时候这个锁过期自动删除了（发生异常的时候可能也没有走完整个逻辑），线程二又正好设置了锁进来了。线程一就又误删了锁，还是会有并发的问题

![截屏2022-11-25 19.43.04](img/%E6%88%AA%E5%B1%8F2022-11-25%2019.43.04.png)

**原因就在于，删除锁的判断和删除两个操作并不是原子性的，可能会被其他redis操作插入其中，导致并发问题。使用Lua脚本，保证多个redis操作的原子性**

# Lua脚本的使用

```redis
eval "return redis.call('set', 'name', 'jack')" 0
```

redis的key和value本质都是字符串，但是算是两种类型，因此如果key和value不想写死，那就在后面跟上 数字 + 字符串组，数字表明这个字符串中前多少个是key类型的字符串，这些字符串放入KEYS数组，后面就全是value的，放入ARGV数组。0就代表啥也没有。**在真正的代码用的时候，两个数组都直接封装成list集合了，都不需要写那个数字参数**

```redis
eval "return redis.call('set', KEYS[1], ARGV[1])" 1 name Rose
```

字符数组必须大写，eval后面必须跟双引号

# 使用脚本来解决并发问题

**1、提前加载lua脚本文件，防止使用的时候有io流的阻塞**

static代码块就是类加载的时候会执行一次的代码

```
new ClassPathResource("luas/unlock.lua")
```

直接使用Resource下的文件

# 分布式锁-redission

原先自己写的锁存在的问题

1、锁不可重入

2、锁不可重试，失败了就直接返回

3、超时释放还是有问题，锁时间的估计万一出问题了呢

4、主从一致性，锁没同步，主就挂了，这个锁就不存在了，其他线程就能拿到锁了
