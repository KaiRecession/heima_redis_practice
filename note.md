# 依赖说明

```java
// redis java端的依赖			
<dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-data-redis</artifactId>
        </dependency>
  // redis数据库连接池的依赖
        <dependency>
            <groupId>org.apache.commons</groupId>
            <artifactId>commons-pool2</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>

        <dependency>
            <groupId>mysql</groupId>
            <artifactId>mysql-connector-java</artifactId>
            <scope>runtime</scope>
            <version>5.1.47</version>
        </dependency>
  // 提供一些方便的注解
        <dependency>
            <groupId>org.projectlombok</groupId>
            <artifactId>lombok</artifactId>
            <optional>true</optional>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-test</artifactId>
            <scope>test</scope>
        </dependency>
  // mybatis单表增删改查的简化
        <dependency>
            <groupId>com.baomidou</groupId>
            <artifactId>mybatis-plus-boot-starter</artifactId>
            <version>3.4.3</version>
        </dependency>
        <!--hutool-->
  // json处理、字符串处理等工具类
        <dependency>
            <groupId>cn.hutool</groupId>
            <artifactId>hutool-all</artifactId>
            <version>5.7.17</version>
        </dependency>
```

# 短信登录功能

### 基于session实现

dto：DTO就是数据传输对象(Data Transfer Object)的缩写。 DTO模式，是指将数据封装成普通的JavaBeans，在J2EE多个层次之间传输。 DTO类似信使，是同步系统中的Message。 该JavaBeans可以是一个数据模型Model。  

使用接口中没有的方法，写出来后直接根据提示创建接口方法在相应的接口中就行，跳到接口中后再次点击左边中的绿色小圆点（小圆点中有个I）直接跳转到接口的实现类中去

# ThreadLocal

<img src="img/%E6%88%AA%E5%B1%8F2022-10-17%2009.51.32.png" alt="截屏2022-10-17 09.51.32" style="zoom:50%;" />

每个线程都会有属于自己的本地内存，在堆（也就是上图的主内存）中的变量在被线程使用的时候会被复制一个副本线程的本地内存中，当线程修改了共享变量之后就会通过JMM管理控制写会到主内存中。

 很明显，在多线程的场景下，当有多个线程对共享变量进行修改的时候，就会出现线程安全问题，即数据不一致问题。常用的解决方法是对访问共享变量的代码加锁（synchronized或者Lock）。但是这种方式对性能的耗费比较大。在JDK1.2中引入了ThreadLocal类，来修饰共享变量，使每个线程都单独拥有一份共享变量，这样就可以做到线程之间对于共享变量的隔离问题。

**JDK8之后，每个Thread维护一个ThreadLocalMap对象，这个Map的key是ThreadLocal实例本身，value是存储的值要隔离的变量，是泛型**

一般都会将ThreadLocal声明成一个静态字段，因为线程里面有私有的Map变量去存储各个ThreadLocal的value，map的key就是ThreadLocal对象，想要获取就必须获得ThreadLoacl对象，**不同的线程拿到相同的ThreadLocal在自己线程的map中获取value也不同。**

ThreadLocal对象里面的save方法首先就会拿到当前线程，然后再往下进行，这样就顺起来了

**就是为了给线程这个对象注入自己的私有变量（User对象），每个线程都读自己被注入的属性，但是ThreadLocal又作为公共的key，可以在任何地方写**

# 拦截器

**将校验用户是否登录的操作代码提取出来，其他的各种Controller就不用再校验，拦截器将校验出来的结果通过ThreadLocal进行传递，完美这样子，看一下线程对于tomcat 的意义**

1、编写拦截器的代码，继承HandlerInterceptor，里面的三个方法返回值为boolean，并且是这个接口的default方法，就算不implement也能够使用

2、将便携好的拦截器配到spring中去。

* 新建一个配置类实现WebMvcConfigurer接口
* 覆盖方法addInterceptors，使用方法的形参对象的addInterceptor中放入new好的刚刚写的拦截器类的对象，再配置一下路径
* 最后上面加上Configuration的注解即可

拦截器里面的redis注入只能通过构造函数进行注入，因为拦截器的代码是写在一个里面，这个类是不进行spring注入的

**看代码的报错直接看第一行的报错或者看log信息**

# Redis短信登录

Tomcat的session共享比较la，建议使用redis集群来取代session机制

在发送短信验证码时的key使用电话号码取代session的code属性，在验证用户是否登录时key使用token来取代session的user属性

## 两个拦截器的作用

<img src="img/%E6%88%AA%E5%B1%8F2022-11-06%2016.45.31.png" alt="截屏2022-11-06 16.45.31" style="zoom:80%;" />

第一个拦截器只是查看当前用户的token有没有以及有没有过期，有token并且没过期就放入ThreadLocal中去方便需要用户信息的拦截器获取，并且刷新token的有效期，这个拦截器不会拦截，放行所有请求，唯一的目的就是为了刷新tocken，**因为用户访问网站的所有网页都需要刷新tocken，但是并不是所有的网页都需要token信息，所以只能这样写而不是将刷新token写到第二个拦截器中**

# 缓存

## 缓存更新策略

1、**内存淘汰：**redis自动进行，当redis内存达到咱们设定的max-memery的时候，会自动触发淘汰机制，淘汰掉一些不重要的数据(可以自己设置策略方式)。无维护成本，但是一致性很差，**感觉就没有一致性的保证**

2、**超时剔除：**当我们给redis设置了过期时间ttl之后，redis会将超时的数据进行删除，方便咱们继续使用缓存。**这个也基本没有一致性**

3、**主动更新：**我们可以手动调用方法把缓存删掉，通常用于解决缓存和数据库不一致问题

**使用主动更新加上兜底（超时剔除）来保证高一致性**

## 主动更新的策略

1、**操作数据库更新数据后，删除缓存而不是更新缓存**。假设我们每次操作数据库后，都操作缓存，但是中间如果没有人查询，那么这个更新动作实际上只有最后一次生效，中间的更新动作意义并不大

2、**先操作数据库，再删除缓存**。原因在于，如果你选择第一种方案，在两个线程并发来访问时，假设线程1更新数据库，他**先把缓存删了**，此时线程2过来，他查询缓存数据并不存在，此时他写入缓存（查到的还是旧数据），当他写入缓存后，线程1再执行更新动作时（因为是先操删缓存后操作的数据库），实际上写入的就是旧的数据，新的数据被旧数据覆盖了。这就导致了缓存更新不到最新值

<img src="img/%E6%88%AA%E5%B1%8F2022-11-06%2020.01.12.png" alt="截屏2022-11-06 20.01.12" style="zoom:80%;" />

**但其实先操作数据库后删除缓存可以保证缓存可以更新到最新值，但是当数据库更新完毕没有删除缓存时，拿到的还是旧值，会有一个间隙的数据不一致**

两部分逻辑，第一部分是将数据从数据库放入缓存

第二部分才是这个数据库更新后操作缓存的逻辑

## 将数据放入缓存的逻辑操作

1、查询redis缓存

2、存在返回成功，不存在去数据库查询

3、数据库查询不到返回失败，查询到了就放入缓存中，**同时设置过期时间作为兜底**，然后返回查询结果

## 数据库更新后操作缓存的逻辑

**拦截器的拦截地址一定要加“/”，一定要是斜杠开头**

1、获取id

2、传入的id为空，就返回失败

3、**更新数据库，删除缓存，返回ok**

4、**给这一系列操作加上事务**

# 缓存穿透

用户请求的数据在缓存中和数据库中都不存在，不断发起这样的请求，给数据库带来巨大压力

解决方案

1、布隆过滤器

布隆过滤器原理：

布隆过滤器的实现原理是一个超大的**位数组**和**几个哈希函数**。假设有K个哈希函数，对于集合里面的每一个元素，将元素依次通过 k个哈希函数进行映射，每次映射都会产生一个哈希值，这个值对应位数组上面的一个点，然后将位数组对应的位置标记为 1。查询某元素是否存在集合中的时，用同样的方法将 W 通过哈希映射到位数组上的 3 个点。如果 3 个点中任意一个点不为 1，则可以判断该元素一定不存在集合中。反之，如果 3 个点都为 1，则该元素可能存在集合中。注意：此处不能判断该元素是否一定存在集合中，可能存在一定的误判率

2、缓存null值

3、增加id复杂度，避免猜测

4、做好数据的基础格式校验

5、加强用户权限

6、做好热点参数的限流

直接加两句代码就解决了

# 缓存雪崩

缓存雪崩是指在同一时段**大量的缓存key同时失效或者Redis服务宕机**，导致大量请求到达数据库，带来巨大压力。

解决方案：

* 给不同的Key的TTL添加随机值
* 利用Redis集群提高服务的可用性
* 给缓存业务添加降级限流策略
* 给业务添加多级缓存

<img src="img/%E6%88%AA%E5%B1%8F2022-11-14%2019.42.48.png" alt="截屏2022-11-14 19.42.48" style="zoom:80%;" />

# 缓存击穿

缓存击穿问题也叫热点Key问题，就是一个被高并发访问**并且缓存重建业务较复杂**的key突然失效了，无数的请求访问会在瞬间给数据库带来巨大的冲击。

就是说这个key的缓存失效了，需要从数据库拿出来重新缓存一下，但是这个过程的时间较长，在这个过程中，恰巧这个key还是一个热点key，很多请求都在这个时间段来了，发现没有缓存，然后都去数据库找，准备重建缓存，这不就崩了

**缓存穿透是两层，击穿就是击穿了缓存层。穿透比较彻底**

<img src="img/%E6%88%AA%E5%B1%8F2022-11-14%2020.28.29.png" alt="截屏2022-11-14 20.28.29" style="zoom:80%;" />

解决方案一、使用锁来解决：

因为锁能实现互斥性。假设线程过来，只能一个人一个人的来访问数据库，从而避免对于数据库访问压力过大，但这也会影响查询的性能，因为此时会让查询的性能从并行变成了串行，我们可以采用tryLock方法 + double check来解决这样的问题。

假设现在线程1过来访问，他查询缓存没有命中，但是此时他获得到了锁的资源，那么线程1就会一个人去执行逻辑，假设现在线程2过来，线程2在执行过程中，并没有获得到锁，那么线程2就可以进行到休眠，直到线程1把锁释放后，线程2获得到锁，然后再来执行逻辑，此时就能够从缓存中拿到数据了。

解决方案二、逻辑过期方案

方案分析：我们之所以会出现这个缓存击穿问题，主要原因是在于我们对key设置了过期时间，假设我们不设置过期时间，其实就不会有缓存击穿的问题，但是不设置过期时间，这样数据不就一直占用我们内存了吗，我们可以采用逻辑过期方案。

我们把过期时间设置在 redis的value中，注意：这个过期时间并不会直接作用于redis，而是我们后续通过逻辑去处理。假设线程1去查询缓存，然后从value中判断出来当前的数据已经过期了，此时线程1去获得互斥锁，那么其他线程会进行阻塞，获得了锁的线程他会开启一个 线程去进行 以前的重构数据的逻辑，直到新开的线程完成这个逻辑后，才释放锁， 而线程1直接进行返回，假设现在**线程3过来访问，由于线程线程2持有着锁，所以线程3无法获得锁，线程3也直接返回数据**，只有等到新开的线程2把重建数据构建完后，其他线程才能走返回正确的数据。

这种方案巧妙在于，异步的构建缓存，缺点在于在构建完缓存之前，**返回的都是脏数据**。直接看图片就行，**在重建完成之前返回的都是过期的数据**

![截屏2022-11-14 20.30.41](img/%E6%88%AA%E5%B1%8F2022-11-14%2020.30.41.png)

# 使用互斥锁解决缓存击穿

## 利用redis的键做分布式锁

redis中有一个setnx（set key **only if not exist**），只有key不存在才会成功，存在了就不会成功。redis又是单线程，所以就能当锁，牛逼

**释放锁的时候就把他删掉 del key，加一个有效期作为兜底**

**当拿到锁的时候应该double check一下，参考多线程的设计模式**

# 使用逻辑过期方式解决缓存击穿

为key设置一个逻辑过期时间，当检查到过期时使用互斥锁去新建一个线程更新缓存，然后立即返回这个过期缓存。理论上逻辑过期时互斥锁的复杂版，他一致性会差一点，慢一点儿

# 分布式系统下唯一随机ID的生成

 就是在前面加了32位的时间差转换成的时间戳再与上一个32位的自增键，按照每天设置一个不同键，键就用日期来设置。这样设置，UUID不能保证单调递增，这个可以，而且性能比UUID好

# 秒杀券

注意秒杀券的截止时间要设置成大于当前的时间前端才能够显示

1、判断时间是否在规定的时间内

2、判断库存

3、update数据库，将库存的值减一，判断数据是否更新成功

4、生成优惠券订单的id，关联优惠券和用户的id，总共三个id

5、写入优惠券订单表，但会成功

6、给方法加上事务

## 超卖问题

本质就是多线程的问题

使用CAS无锁（乐观锁）的方式，mysql的update是自己有锁的，锁的类型有点复杂，以后再看

# 一人一单问题

之前使用无锁的方式是因为是修改操作

**一人一单问题判断的是记录存不存在，就是存在问题，就不能使用无锁的方式**

使用悲观锁

1、降低锁的粒度，使用userID加锁，并使用String的intern方法（感觉会被回收器回收，不一定可靠）

2、锁的范围要大于事务范围，但是事务的代码使用代理对象生成的，因此，在锁的代码块中，应该使用代理对象调用事务的代码

感觉怎么看都不可靠

# 在集群下的并发问题

在集群的时候，jvm不同，锁就不同了，就有问题了

idea开启两个相同服务：

1、在左下角的Service中点击原本的8081项目，右击，拷贝配置

2、在弹出的界面中给vmoptinos中修改端口 -Dserver.port=8082，确定即可，然后就能一起启动了

在nginx开启负载均衡

1、修改代理的语句为：

```xml
proxy_pass http://backend;
```

2、修改backend

```xml
upstream backend {
        server 192.168.248.58:8081 max_fails=5 fail_timeout=10s weight=1;
        server 192.168.248.58:8082 max_fails=5 fail_timeout=10s weight=1;
    } 
```

nginx默认时轮询机制，一人一次轮回来

并发问题不好延时，要用debug来，跳过，反正就是这个锁名义上一样，但是不在同一个虚拟机中就不一样了，可以同时进入两个线程进行抢单，同一个人就能下单两次

**搞清楚要看的是同一个人在并发下同时抢单的问题**，**所以锁应该用用户ID，降低锁的粒度**

# 分布式锁

简单的使用redis锁，redis锁的过期时间要大于预估的业务执行的最长时间。当获取redis锁之前就已经判断了当前用户没有下过单以及库存充足的问题，为了防止并发多次下单问题才使用的分布式锁。简单的设置，在获取锁代码不出异常的时候应该是可以用的，在集群下测试也是正常

# 分布式锁误删的情况

1、持有锁的线程内部执行代码时间过长，导致分布式锁超时自动释放。这时第二个线程就可以拿到锁，然后第一个线程执行完又给线程二的锁删了，线程三又进来了。这样就有两个阶段是有两个线程并行在执行。**在执行一人一单的时候就可能发生一个人下单三次**

![截屏2022-11-25 18.44.12](img/%E6%88%AA%E5%B1%8F2022-11-25%2018.44.12.png)

解决办法，在获取锁的时候把锁的value存入线程的唯一标识符（UUID加上线程id）。解锁的时候，首先判断锁是否是本线程设置的锁，如果不是就不删除

2、更极端的情况，线程一已经判断了这个锁是本线程的锁，但是准备删除的时候这个锁过期自动删除了（发生异常的时候可能也没有走完整个逻辑），线程二又正好设置了锁进来了。线程一就又误删了锁，还是会有并发的问题

![截屏2022-11-25 19.43.04](img/%E6%88%AA%E5%B1%8F2022-11-25%2019.43.04.png)

**原因就在于，删除锁的判断和删除两个操作并不是原子性的，可能会被其他redis操作插入其中，导致并发问题。使用Lua脚本，保证多个redis操作的原子性**

# Lua脚本的使用

```redis
eval "return redis.call('set', 'name', 'jack')" 0
```

redis的key和value本质都是字符串，但是算是两种类型，因此如果key和value不想写死，那就在后面跟上 数字 + 字符串组，数字表明这个字符串中前多少个是key类型的字符串，这些字符串放入KEYS数组，后面就全是value的，放入ARGV数组。0就代表啥也没有。**在真正的代码用的时候，两个数组都直接封装成list集合了，都不需要写那个数字参数**

**数组的下标从1开始算**

```redis
eval "return redis.call('set', KEYS[1], ARGV[1])" 1 name Rose
```

字符数组必须大写，eval后面必须跟双引号

# 使用脚本来解决并发问题

**1、提前加载lua脚本文件，防止使用的时候有io流的阻塞**

static代码块就是类加载的时候会执行一次的代码

```
new ClassPathResource("luas/unlock.lua")
```

直接使用Resource下的文件

# 分布式锁-redisson

原先自己写的锁存在的问题

1、锁不可重入

2、锁不可重试，失败了就直接返回

3、超时释放还是有问题，锁时间的估计万一出问题了呢

4、主从一致性，锁没同步，主就挂了，这个锁就不存在了，其他线程就能拿到锁了

**Redisson极端情况也会有问题吧？**

源码中好像解决了这两个极端问题

## redisson可重入原理

在Lock锁中，他是借助于底层的一个voaltile的一个state变量来记录重入的状态的，比如当前没有人持有这把锁，那么state=0，假如有人持有这把锁，那么state=1，如果持有这把锁的人再次持有这把锁，那么state就会+1 ，如果是对于synchronized而言，他在c语言代码中会有一个count，原理和state类似，也是重入一次就加一，释放一次就-1 ，直到减少成0 时，表示当前这把锁没有被人持有。  

在分布式锁中，他采用hash结构用来存储锁，其中大key表示表示这把锁是否存在

这时候获取锁就不适用setnx了，用的就是exists

redisson里面有内置的lua脚本，还加上了随机数和线程ID。脚本在删除锁成功的时候会带上通知，**发布锁删除的消息**

## redisson重试的原理

在获取锁的lua脚本中，获取成功了返回null，获取失败了就返回所的剩余有效期，剩余有效期用的是pttl命令，返回的单位是毫秒

如果ttl不为null，用等待时间减去获取锁的时间，小于0就失败。否则订阅这个锁的删除消息（future消息阻塞，不占用cpu资源），等待时间就位剩余的等待时间。超时了就失败，没超时就肯定收到了删除消息，再次try获取锁，看ttl是否为null，剩下的逻辑就类似。**优点就是没有一直while true保证cpu的占用率不会很高**

# redisson超时的原理

在**拿到锁的时候**首先要保证不会因为业务的阻塞导致有效期到时释放锁的情况（只是leasetime设置为-1的情况）

看门狗，设置延时任务，每个任务里面递归调用自己。就相当于有延时的递归。

当解锁的时候，取消任务，释放锁

假设我们的线程出现了宕机他还会续约吗？当然不会，**因为没有人再去调用renewExpiration这个方法，所以等到时间之后自然就释放了。**

# 主从一致性问题

为了解决这个问题，redission提出来了MutiLock锁，使用这把锁咱们就不使用主从了，每个节点的地位都是一样的， 这把锁加锁的逻辑需要写入到每一个主丛节点上，只有所有的服务器都写入成功，此时才是加锁成功，假设现在某个节点挂了，那么他去获得锁的时候，只要有一个节点拿不到，都不能算是加锁成功，就保证了加锁的可靠性。**也就是保证从节点一定要完整的复制到出问题的主节点的数据**

# 秒杀优化（旁路缓存的改变）

旁路缓存策略以数据库（Hbase,redis）中的数据为准，缓存中的数据是按需加载的，它可以分为读策略和写策略。

读策略：

从缓存中读取数据；如果缓存命中，则直接返回数据；如果缓存不命中，则从数据库中查询数据；查询到数据后，将数据写入到缓存中，并且返回给用户。

写策略：

更新数据库中（HBASE，Redis）的记录；删除缓存记录。


优化思路：

当用户下单之后，判断库存是否充足只需要导redis中去根据key找对应的value是否大于0即可，如果不充足，则直接结束，如果充足，继续在redis中判断用户是否可以下单，如果set集合中没有这条数据，说明他可以下单，如果set集合中没有这条记录，则将userId和优惠卷存入到redis中，并且返回0，整个过程需要保证是原子性的，我们可以使用lua来操作

当以上判断逻辑走完之后，我们可以判断当前redis中返回的结果是否是0 ，如果是0，则表示可以下单，则将之前说的信息存入到到queue中去，然后返回，然后再来个线程异步的下单，前端可以通过返回的订单id来判断是否下单成功。

1、首先，在添加秒杀券的操作后把这个券的信息添加到redis中。**redis的key为前缀加上优惠券的唯一ID，value位库存量**。**再来一个一样的的set类型的key，也是前缀加上优惠券的唯一ID，用来存储本优惠券已经下单用户的ID**

2、lua脚本保证原子性，首先库存key判断库存，订单key判断用户是否下单。都通过了，库存减，用户放，然后将mysql的更新任务添加到消息列表中区，这个消息估计还是要上消息队列的框架，jvm也太不安全了，但是这里就引出了消息队列的必要性。

redis虽然新增了消息队列的结构，但是无论是安全、宕机数据的保存，都不如专门的消息队列框架来的好

# 探店笔记

## 发布笔记

保存图片的方法

```java
 public Result uploadImage(@RequestParam("file") MultipartFile image)
```

然后获取文件名字，将文件数据保存到自己的服务器即可

## 查询笔记

查询笔记的时候，返回笔记和笔记的所属用户。在blog entity中，增加两个属性，并且注解这个两个字段并不属于blog，这两个字段以后手动维护

```java
@TableField(exist = false)
private String name;
```

## 方法引用的使用

lambada表达式的简化罢了，双冒号前面是对象或者类，双冒号后面就是对象的方法或者类的静态方法。这个方法会被编译器自动识别转换成函数式接口注入。jvm并不支持方法引用，只是在编译器层面做了一些工作

## 点赞功能

给blog字段中添加isLike字段

使用redis存储每一个博客点赞用户的所有id，使用set集合存储

封装逻辑：

第一次在bolg中添加user 的名字等属性是为了封装blog是哪个用户封装的

第二次在blog中添加isLike属性，是判断**当前登录的用户**是否点赞本blog。前端只接收一个blog对象就能完成了

这个点赞功能就高度依赖redis，redis删除这个键还是能发生多次点赞。未登录还会导致异常空指针的发生

### 点赞排行榜

取出前五名点赞的用户进行显示

zset中放入key，value，分数，会按照分数进行排名。**分数就使用时间戳**

zset判断是否存在是直接用key查分数，不为null就代表存在

当拿到前5名的id的时候需要去数据库中查询对应的用户，数据库中in字段返回的顺序并不会和查询id的顺序一样，使用order by filed（id， 排名顺序）。这样order会按照设定的顺序返回

# 关注和取关

创建一个数据库表，有id字段和user_id字段以及follow_id，id是主键，所以可以有多条user_id的记录，不影响

，取关就删除记录，关注就新增一个记录

# 共同关注

存进每个用户的粉丝放入set集合，求set的交集即可

# 消息推送（Feed流）

**拉模式：**

该模式的核心含义就是：当张三和李四和王五发了消息后，都会保存在自己的邮箱中，假设赵六要读取信息，那么他会从读取他自己的收件箱，此时系统会从他关注的人群中，把他关注人的信息全部都进行拉取，然后在进行排序

优点：比较节约空间，因为赵六在读信息时，并没有重复读取，而且读取完之后可以把他的收件箱进行清楚。

缺点：比较延迟，当用户读取数据时才去关注的人里边去读取数据，假设用户关注了大量的用户，那么此时就会拉取海量的内容，对服务器压力巨大。

**推模式：**

推模式是没有写邮箱的，当张三写了一个内容，此时会主动的把张三写的内容发送到他的粉丝收件箱中去，假设此时李四再来读取，就不用再去临时拉取了

优点：时效快，不用临时拉取

缺点：内存压力大，假设一个大V写信息，很多人关注他， 就会写很多分数据到粉丝那边去

**推拉结合模式**：也叫做读写混合，兼具推和拉两种模式的优点。

推拉模式是一个折中的方案，站在发件人这一段，如果是个普通的人，那么我们采用写扩散的方式，直接把数据写入到他的粉丝中去，因为普通的人他的粉丝关注量比较小，所以这样做没有压力，如果是大V，那么他是直接将数据先写入到一份到发件箱里边去，然后再直接写一份到活跃粉丝收件箱里边去，现在站在收件人这端来看，如果是活跃粉丝，那么大V和普通的人发的都会直接写入到自己收件箱里边来，而如果是普通的粉丝，由于他们上线不是很频繁，所以等他们上线时，再从发件箱里边去拉信息。

使用推模式：

如果使用list集合排序，角标是在动态变化的。所以使用sortedSet记录得分，下次找小于得分。这样在一次查询的过程中不会受到新数据插入的影响，也脱离了角标的依赖

发博客的时候将博客id发送给每一个粉丝的收件箱（每一个粉丝有一个redis的sortedSet集合）

更新的时候，每个人只用看自己的收件箱就行了，按照时间顺序进行查询，收件箱存有博客ID

# 附近商铺

利用redis提供的经纬度计算来实现

redis中只存储商铺的id和经纬度，拿到id后再去数据库查。商铺类型分开key设置GEO集合

# 用户签到

使用redis的bitmap数据结构，Redis中是利用string类型数据结构实现BitMap，因此最大上限是512M，转换为bit则是 2^32个bit位。

感觉没啥好学的这一功能，过

# UV统计

首先我们搞懂两个概念：

* UV：全称Unique Visitor，也叫**独立访客量**，是指通过互联网访问、浏览这个网页的自然人。1天内同一个用户多次访问该网站，只记录1次。
* PV：全称Page View，也叫**页面访问量或点击量**，用户每访问网站的一个页面，记录1次PV，用户多次打开页面，则记录多次PV。往往用来衡量网站的流量。

通常来说UV会比PV大很多，所以衡量同一个网站的访问量，我们需要综合考虑很多因素，所以我们只是单纯的把这两个值作为一个参考值

UV统计在服务端做会比较麻烦，因为要判断该用户是否已经统计过了，需要将统计过的用户信息保存。但是如果每个访问的用户都保存到Redis中，数据量会非常恐怖，那怎么处理呢？

Hyperloglog(HLL)是从Loglog算法派生的概率算法，用于确定非常大的集合的基数，而不需要存储其所有值。相关算法原理大家可以参考：https://juejin.cn/post/6844903785744056333#heading-0
Redis中的HLL是基于string结构实现的，单个HLL的内存**永远小于16kb**，**内存占用低**的令人发指！作为代价，其测量结果是概率性的，**有小于0.81％的误差**。不过对于UV统计来说，这完全可以忽略。

```redis
pfadd key value1 value2 ...  向集合中添加元素
pfcount key 统计这个集合里面的元素 这个数据结构能够保证元素不重复
统计出来的结果会有误差，但是内存占用很小
```

